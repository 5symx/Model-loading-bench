# Model-loading-bench

Data transfer through device for HF PyTorch model

## Update the HF model for bench.py

In order to avoid the error with 'meta device no data', update the `register_buffer` function in the LLAVA model in `transformers/models/llama/modeling_llama.py` and `transformers/models/clip/modeling_clip.py` by setting the parameter to `persistent=True`. 

# MMLU benchmark for Llama

1. Download dataset through Original implementation of MMLU. https://github.com/hendrycks/test

2. Install transformer. `pip install transformers` 

3. Run MMLU evaluation benchmark. 
   ```bash
   python llama/run_mmlu.py --ckpt_dir meta-llama/Llama-2-7b-chat-hf --param_size 7 --model_type llama | tee llama/output.log
   ```

   If `snapshot_memory` is True, the *.pickle file of memory usage will be generated by pytorch allocator. And it could be viewed on website viewer https://pytorch.org/memory_viz.

4. Extract the log file to generate the plot of memory usage through processing.
   ```bash
   python llama/extract_log.py
   ```

# MM-VET benchmark for Llava

1. Download MM-VET dataset from https://github.com/yuweihao/MM-Vet/releases/download/v1/mm-vet.zip

2. Run MM-VET evaluation refer to https://github.com/haotian-liu/LLaVA/blob/main/docs/Evaluation.md
   ```bash
   python llava/bench_vqa.py
   ```
 3. Todo