# MMLU benchmark for Llama

1. Download dataset through Original implementation of MMLU. https://github.com/hendrycks/test

2. Install transformer. `pip install transformers` 

3. Run MMLU evaluation benchmark. 
   ```bash
   python llama/run_mmlu.py --ckpt_dir meta-llama/Llama-2-7b-chat-hf --param_size 7 --model_type llama | tee llama/output.log
   ```

   If `snapshot_memory` is True, the *.pickle file of memory usage will be generated by pytorch allocator. And it could be viewed on website viewer https://pytorch.org/memory_viz.

4. Extract the log file to generate the plot of memory usage through processing.
   ```bash
   python llama/extract_log.py
   ```
